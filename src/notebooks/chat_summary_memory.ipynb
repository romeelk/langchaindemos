{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n",
      "Nice to meet you, Tom! How can I assist you today?\n",
      "It's great to meet you, Tom! Plumbing is such an important job. How can I assist you today? Are you looking for tips, advice, or something specific related to your work?\n",
      "I have a good amount of information about plumbing! I can provide insights on various topics, including common plumbing problems like leaks, clogs, and water pressure issues, as well as tips for installation and maintenance. I can also discuss tools you might need, plumbing codes and regulations, and best practices for different types of plumbing systems. If there's something specific you're curious about or need help with, just let me know!\n",
      "You're right; I'm not human and I don't have thoughts or feelings like a person does. However, I'm here to provide information and assistance based on the data I've been trained on. If you have any questions or need help with something specific, feel free to ask!\n",
      "Goodbye, Tom! If you ever have more questions or need assistance, feel free to reach out. Have a great day!\n",
      "I apologize for the misunderstanding! What would you like me to call you? How can I assist you today?\n",
      "It seems like you might be using a phrase or expression I'm not familiar with. Could you clarify what you mean by \"Zootam wey\"? I'm here to help!\n",
      "I apologize for the confusion! \"Zootam\" isn't a term I'm familiar with in the context of my training data. It could be a slang term, a regional expression, or something specific that isn't widely recognized. If you could provide more context or explain what it means, I'd be happy to learn and assist you further!\n",
      "Exited prompt chat\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "import os\n",
    "import getpass\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(prompt=\"Enter OpenApi key:\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", verbose=True)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm, memory_key=\"messages\",return_messages=True)\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\",\"messages\"],\n",
    "    messages=[\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")])\n",
    "\n",
    "chain  = LLMChain(llm=llm, memory=memory, prompt = prompt)\n",
    "\n",
    "try:\n",
    "    while True:    \n",
    "        content = input(\">>\")\n",
    "        \n",
    "        if content == \"exit\":\n",
    "            break\n",
    "        result = chain({\"content\":content})\n",
    "\n",
    "        print(result[\"text\"])\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Ctrl-C pressed!\")\n",
    "    sys.exit(0)\n",
    "\n",
    "print(\"Exited prompt chat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
