{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/80/965xts3n22bbbvj7_147hmkh0000gn/T/ipykernel_55592/2490575986.py:15: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=llm, memory_key=\"messages\",return_messages=True)\n",
      "/var/folders/80/965xts3n22bbbvj7_147hmkh0000gn/T/ipykernel_55592/2490575986.py:22: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain  = LLMChain(llm=llm, memory=memory, prompt = prompt)\n",
      "/var/folders/80/965xts3n22bbbvj7_147hmkh0000gn/T/ipykernel_55592/2490575986.py:30: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = chain({\"content\":content})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n",
      "Hello, Romeel! It's great to meet you. How can I assist you today?\n",
      "Your name is Romeel. How can I assist you today?\n",
      "That's great, Romeel! IT is such a dynamic field with a lot of exciting developments. What specific area of IT do you work in? And how can I assist you today?\n",
      "You mentioned that you work in IT. If you'd like to share more details about your specific role or area of expertise within IT, Iâ€™d be happy to assist you with any questions or topics related to your work!\n",
      "Exited prompt chat\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import MessagesPlaceholder, HumanMessagePromptTemplate\n",
    "import os\n",
    "import getpass\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(prompt=\"Enter OpenApi key:\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", verbose=True)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm, memory_key=\"messages\",return_messages=True)\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\",\"messages\"],\n",
    "    messages=[\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")])\n",
    "\n",
    "chain  = LLMChain(llm=llm, memory=memory, prompt = prompt)\n",
    "\n",
    "try:\n",
    "    while True:    \n",
    "        content = input(\">>\")\n",
    "        \n",
    "        if content == \"exit\":\n",
    "            break\n",
    "        result = chain({\"content\":content})\n",
    "\n",
    "        print(result[\"text\"])\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Ctrl-C pressed!\")\n",
    "    sys.exit(0)\n",
    "\n",
    "print(\"Exited prompt chat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
